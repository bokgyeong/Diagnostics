{
    "collab_server" : "",
    "contents" : "### PRE-STEP: Particle selection =====================================\n\n# ABC method\npartABC = function(X, stat, m, d, num){ # d: no of particles\n  # Step 1: Select a rectangle domain\n  p = 2                                          # dimension of parameter\n  wth = 5\n  # wth = 12\n  Domain = matrix(c(m$coef[1] - wth*sqrt(m$covar[1,1]), m$coef[1] + wth*sqrt(m$covar[1,1]) ,\n                    m$coef[2] - wth*sqrt(m$covar[2,2]), m$coef[2] + wth*sqrt(m$covar[2,2])),2,p)  \n  num.point = 3000           \n  th = matrix(0,num.point,p)\n  \n  # Step 2: Generate D Latin hypercube design points over the domain D_1\n  Design = lhsDesign(n=num.point, dimension=p, randomized=TRUE, seed=1)\n  th = Design$design\n  th[,1] = (Domain[2,1]-Domain[1,1])*th[,1]+Domain[1,1]\n  th[,2] = (Domain[2,2]-Domain[1,2])*th[,2]+Domain[1,2]\n  \n  # Step 3: Simulate the auxiliary variable for each design point\n  summat = pAuxSamp(X, 1, th, 1, num)\n  \n  # Step 4: Choose some of them based on the distance b/w simulated and observed summary statistics\n  dist = sqrt(  apply(  ( matrix( rep(stat, num.point), num.point, byrow = T) - summat[1:num.point,,1] )^2, 1, sum ) )\n  eps = quantile(dist, probs = 0.03)\n  m =  apply(  th[which(dist < eps),], 2, mean)\n  S = cov( th[which(dist < eps),] )\n  num.point = d                     # suppose we have 'num.point' particles\n  thABC = mvrnorm(num.point, m, S)\n  \n  # Step 5: Select a samller rectangular domain D_2 in D_1\n  Domain = rbind(apply(thABC,2,min), apply(thABC,2,max))  \n  th = matrix(0,num.point,p)\n  \n  # Step 6: Generate d number of particles over the domain\n  Design = lhsDesign(n=num.point, dimension=p, randomized=TRUE, seed=1)\n  th = Design$design\n  th[,1] = (Domain[2,1]-Domain[1,1])*th[,1]+Domain[1,1]\n  th[,2] = (Domain[2,2]-Domain[1,2])*th[,2]+Domain[1,2]\n  \n  return(list(th, thABC))\n}\n\n\n### Gaussian Process MCMC (particles generated using ABC)\nGPmcmcErgm = function(Niter, X, stat, parts, impReg, N, cycle, num, LikEm = FALSE){ # N: no of importance samples\n  num.point = nrow(parts) # no of particles\n  \n  ### (Step 1) Generate N sets of auxiliary variables for the sample mean of the particles\n  hat = apply(impReg, 2, mean)\n  Sample = pResponseErgm(X, cycle, hat, N, num)                      # summary statistics\n  \n  \n  ### (Step 2) Calculate importance sampling approximation to log normalizing function\n  # IS approximation to the normalizing constant\n  y = c()\n  for(i in 1:num.point){\n    cal = Sample%*%(parts[i,]-hat)\n    mx = max(cal)\n    y[i] = mx + log( mean( exp(cal-mx) ) )\n  }\n  \n  if(LikEm){\n    # unnormalized likelihood\n    lhX = c()\n    for(i in 1:num.point){ lhX[i] = stat%*%parts[i,] }\n    \n    # full likelihood\n    y = lhX - y\n  } \n  \n  \n  ### (Step 3) Fit a Gaussian process\n  m = km(~ ., design = parts[1:num.point,], response = matrix(y[1:num.point],num.point,1), covtype = \"matern3_2\")\n  \n  # GLS beta coefficients\n  beta.hat.gls = c(coef(m)$trend1,coef(m)$trend2,coef(m)$trend3)\n  range.hat = coef(m)$range\n  sd2.hat = coef(m)$sd2\n  \n  \n  ### (Step 4) Propose\n  # initial theta and covariance matrix for proposal\n  theta = matrix(hat,1)\n  COV = cov(impReg)\n  \n  # calculating an initial value for the normalizing ftn / full likelihood\n  l.h.X = as.numeric(hat%*%stat)\n  \n  # Kriging\n  x.point = data.frame( t(theta[1,]) )\n  pred.m = predict(m, x.point, \"UK\")\n  lhXZ = ypred = pred.m$mean\n  \n  if(LikEm){\n    th = GPmcmcErgmLik(Niter, theta, COV, lhXZ, beta.hat.gls, c(range.hat, sd2.hat), parts, y, stat)[-1,]\n  } else {\n    th = GPmcmcErgmNorm(Niter, theta, COV, lhXZ, beta.hat.gls, c(range.hat, sd2.hat), parts, y, stat)[-1,]\n  }\n  \n  return(th)\n}\n\n\n\n# ### Gaussian Process MCMC (particle generated using DMH)\n# GPmcmcErgm2 = function(Niter, X, stat, m, COV, Nparticles, Nestimates, num, LikEm = FALSE){\n#   ### PRE-STEP: DMH for choosing particles ------------------------------------\n#   aux.par <- matrix(0, Nparticles, 2)\n#   \n#   Nouter = Nparticles*50 + 500\n#   Liang <- ergmDMH(X, COV, matrix(m, ncol=2), Nouter, 1)  \n#   \n#   Liang <- Liang[501:Nouter,]                               # burn in 500\n#   stand <-  sapply(1:2, function(i) (Liang[,i]-min(Liang[,i]))/(max(Liang[,i])-min(Liang[,i]))) # standardized\n#   stand <- unique(stand)                                   # only take unique components\n#   dmat <- rdist(stand)                                     # distance mat\n#   \n#   # choose auxiliary parameters through min max procedure\n#   ind = 1; A = 1; Ac = 2:nrow(stand)\n#   aux.par[1,] = stand[ind,]\n#   \n#   ind = which.max( dmat[,A] )\n#   A = c(A,ind)\n#   Ac = Ac[-which(Ac==ind)]\n#   aux.par[2,] = stand[ind,]\n#   \n#   \n#   for(i in 3:Nparticles){\n#     dummy = max( apply( dmat[,A] , 1, min )[Ac] )\n#     ind = which( dmat[,A] == dummy  )\n#     if(ind < dim(dmat)[1]){ ind = ind }else{ ind = ind-floor( ind/dim(dmat)[1] )*dim(dmat)[1] }\n#     A = c(A,ind)\n#     Ac = Ac[-which(Ac==ind)]\n#     aux.par[i,] = stand[ind,]\n#   }\n#   \n#   dist.aux.par = rdist(aux.par)  # distance matrix for aux.par (for standardized version)\n#   aux.par = sapply(1:2, function(i) (max(Liang[,i])-min(Liang[,i]))*aux.par[,i] + min(Liang[,i]))\n#   \n#   # par(mfrow=c(1,2))\n#   # plot(aux.par, ylim = c(-1, 1.5), xlim = c(-3, 1))\n#   # points(trth[1], trth[2], col=\"red\")\n#   \n#   ### Fucgion emulation algorithm ------------------------------------------\n#   ### (Step 1) Generate N sets of auxiliary variables for the sample mean of the particles\n#   hat = apply(aux.par, 2, mean)\n#   Sample = pResponseErgm(X, 1, hat, Nestimates, num)                      # summary statistics\n#   \n#   \n#   ### (Step 2) Calculate importance sampling approximation to log normalizing function\n#   # IS approximation to the normalizing constant\n#   y = c()\n#   for(i in 1:Nparticles){\n#     cal = Sample%*%(aux.par[i,]-hat)\n#     mx = max(cal)\n#     y[i] = mx + log( mean( exp(cal-mx) ) )\n#   }\n#   \n#   if(LikEm){\n#     # unnormalized likelihood\n#     lhX = c()\n#     for(i in 1:num.point){ lhX[i] = stat%*%th[i,] }\n#     \n#     # full likelihood\n#     y = lhX - y\n#   } \n#   \n#   \n#   ### (Step 3) Fit a Gaussian process\n#   m = km(~ ., design = aux.par[1:Nparticles,], response = matrix(y[1:Nparticles],Nparticles,1), covtype = \"matern3_2\")\n#   \n#   # GLS beta coefficients\n#   beta.hat.gls = c(coef(m)$trend1,coef(m)$trend2,coef(m)$trend3)\n#   range.hat = coef(m)$range\n#   sd2.hat = coef(m)$sd2\n#   \n#   \n#   ### (Step 4) Propose\n#   # initial theta and covariance matrix for proposal\n#   theta = matrix(hat,1)\n#   COV = cov(aux.par)\n#   \n#   # calculating an initial value for the normalizing ftn / full likelihood\n#   l.h.X = as.numeric(hat%*%stat)\n#   \n#   # Kriging\n#   x.point = data.frame( t(theta[1,]) )\n#   pred.m = predict(m, x.point, \"UK\")\n#   lhXZ = ypred = pred.m$mean\n#   \n#   if(LikEm){\n#     th = GPmcmcErgmLik(Niter, theta, COV, lhXZ, beta.hat.gls, c(range.hat, sd2.hat), aux.par, y, stat)[-1,]\n#   } else {\n#     th = GPmcmcErgmNorm(Niter, theta, COV, lhXZ, beta.hat.gls, c(range.hat, sd2.hat), aux.par, y, stat)[-1,]\n#   }\n#   \n#   return(th)\n# }\n\n\n\n\n# ### Gaussian Process MCMC (particle generated using fractional DMH)\n# GPmcmcErgm3 = function(Niter, X, stat, m, COV, Nparticles, Nestimates, num, LikEm = FALSE){\n#   ### PRE-STEP: DMH for choosing particles ------------------------------------\n#   aux.par <- matrix(0, Nparticles, 2)\n#   \n#   Nouter = Nparticles*50 + 500\n#   FLiang <- ergmFDMH(X, COV, matrix(m, ncol=2), Nouter, 10) # multipled by 0.5 in Rcpp\n#   \n#   FLiang <- FLiang[501:Nouter,]                               # burn in 500\n#   stand <-  sapply(1:2, function(i) (FLiang[,i]-min(FLiang[,i]))/(max(FLiang[,i])-min(FLiang[,i]))) # standardized\n#   stand <- unique(stand)                                   # only take unique components\n#   dmat <- rdist(stand)                                     # distance mat\n#   \n#   # choose auxiliary parameters through min max procedure\n#   ind = 1; A = 1; Ac = 2:nrow(stand)\n#   aux.par[1,] = stand[ind,]\n#   \n#   ind = which.max( dmat[,A] )\n#   A = c(A,ind)\n#   Ac = Ac[-which(Ac==ind)]\n#   aux.par[2,] = stand[ind,]\n#   \n#   \n#   for(i in 3:Nparticles){\n#     dummy = max( apply( dmat[,A] , 1, min )[Ac] )\n#     ind = which( dmat[,A] == dummy  )\n#     if(ind < dim(dmat)[1]){ ind = ind }else{ ind = ind-floor( ind/dim(dmat)[1] )*dim(dmat)[1] }\n#     A = c(A,ind)\n#     Ac = Ac[-which(Ac==ind)]\n#     aux.par[i,] = stand[ind,]\n#   }\n#   \n#   dist.aux.par = rdist(aux.par)  # distance matrix for aux.par (for standardized version)\n#   aux.par = sapply(1:2, function(i) (max(FLiang[,i])-min(FLiang[,i]))*aux.par[,i] + min(FLiang[,i]))\n#   \n#   # plot(aux.par, ylim = c(-1, 1.5), xlim = c(-3, 1))\n#   # points(trth[1], trth[2], col=\"red\")\n#   \n#   \n#   ### Fucgion emulation algorithm ------------------------------------------\n#   ### (Step 1) Generate N sets of auxiliary variables for the sample mean of the particles\n#   hat = apply(aux.par, 2, mean)\n#   Sample = pResponseErgm(X, 1, hat, Nestimates, num)                      # summary statistics\n#   \n#   \n#   ### (Step 2) Calculate importance sampling approximation to log normalizing function\n#   # IS approximation to the normalizing constant\n#   y = c()\n#   for(i in 1:Nparticles){\n#     cal = Sample%*%(aux.par[i,]-hat)\n#     mx = max(cal)\n#     y[i] = mx + log( mean( exp(cal-mx) ) )\n#   }\n#   \n#   if(LikEm){\n#     # unnormalized likelihood\n#     lhX = c()\n#     for(i in 1:num.point){ lhX[i] = stat%*%th[i,] }\n#     \n#     # full likelihood\n#     y = lhX - y\n#   } \n#   \n#   \n#   ### (Step 3) Fit a Gaussian process\n#   m = km(~ ., design = aux.par[1:Nparticles,], response = matrix(y[1:Nparticles],Nparticles,1), covtype = \"matern3_2\")\n#   \n#   # GLS beta coefficients\n#   beta.hat.gls = c(coef(m)$trend1,coef(m)$trend2,coef(m)$trend3)\n#   range.hat = coef(m)$range\n#   sd2.hat = coef(m)$sd2\n#   \n#   \n#   ### (Step 4) Propose\n#   # initial theta and covariance matrix for proposal\n#   theta = matrix(hat,1)\n#   COV = cov(aux.par)\n#   \n#   # calculating an initial value for the normalizing ftn / full likelihood\n#   l.h.X = as.numeric(hat%*%stat)\n#   \n#   # Kriging\n#   x.point = data.frame( t(theta[1,]) )\n#   pred.m = predict(m, x.point, \"UK\")\n#   lhXZ = ypred = pred.m$mean\n#   \n#   if(LikEm){\n#     th = GPmcmcErgmLik(Niter, theta, COV, lhXZ, beta.hat.gls, c(range.hat, sd2.hat), aux.par, y, stat)[-1,]\n#   } else {\n#     th = GPmcmcErgmNorm(Niter, theta, COV, lhXZ, beta.hat.gls, c(range.hat, sd2.hat), aux.par, y, stat)[-1,]\n#   }\n#   \n#   return(th)\n# }\n\n\n\n# # Compute Uhat using Rcpp functions\n# ergmUhat = function(X, th, stat, chain, burn, N){\n#   Niter = nrow(th)\n#   J = ncol(th)/2\n#   # Uhat =  matrix(0, Niter, 2)\n#   \n#   Dervlogh = pAuxSamp(X, burn, th[,(2*chain-1):(2*chain)], N, 1)\n#   Uhat = sapply(1:Niter, function(i) stat - rowMeans(Dervlogh[i,,]))\n#   # for(i in 1:Niter){\n#   #   Uhat[i,] = stat - rowMeans(Dervlogh[i,,])\n#   # }\n#   # return(Uhat)\n#   return(t(Uhat))\n# }\n\n\n# # Compute Uhat using simulate function\n# ergmUhat2 = function(data, th, stat, chain, burn, N){\n#   Niter = nrow(th)\n#   J = ncol(th)/2\n#   Uhat =  matrix(0, Niter, 2)\n#   \n#   for(i in 1:Niter){\n#     SimData = simulate(data ~ edges + gwesp(0.25,fixed=TRUE), nsim = N, coef = th[i,(2*chain-1):(2*chain)], control = control.simulate.formula(MCMC.burnin = burn))\n#     Dervlogh = sapply(1:N, function(k) summary(SimData[[k]] ~ edges + gwesp(0.25,fixed=TRUE)))\n#     Uhat[i,] = stat - rowMeans(Dervlogh)\n#   }\n#   return(Uhat)\n# }\n\n# # Compute mu and sigma over time\n# MuSig = function(Uhat){\n#   Niter = nrow(Uhat)\n#   J = ncol(Uhat)/2\n#   mu = sig = matrix(0, Niter, 2)\n#   for(l in 1:2){\n#     k = seq(l, by = 2, length.out = J/2)\n#     for(i in 1:Niter){\n#       if(i == 1){\n#         Ubar = Uhat[1,k]\n#       } else {\n#         Ubar = colMeans(Uhat[(1:i),k])\n#       }\n#       mu[i,l] = mean(Ubar)\n#       sig[i,l] = sd(Ubar)/sqrt(J)\n#     }\n#   }\n#   return(list(mu, sig))\n# }\n\n",
    "created" : 1607908837338.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "962841893",
    "id" : "AA39AFFF",
    "lastKnownWriteTime" : 1607908903,
    "last_content_update" : 1607908903119,
    "path" : "~/work/diagnostics/ergm/magnolia/RFtns.R",
    "project_path" : "RFtns.R",
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}