{
    "collab_server" : "",
    "contents" : "#include <RcppArmadillo.h>\n#include <limits>\n#include <omp.h>\n\n\nusing namespace Rcpp;\nusing namespace arma;\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Generating poisson R.V\nint rPois(double mu){\n  double L = exp(-mu), p = 1;\n  int k = 0;\n  while( p > L ){\n    k = k + 1;\n    p = p*randu();\n  }\n  return(k-1);\t\n}\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// calculating poisson density\ndouble dPois(double k, double mu){\n  double result, denom = k, K=k;\n  \n  if( k == 0 ){ result = exp(-mu); }else{\n    while( k > 1  ){\n      k = k-1;\n      denom = denom*(k);\t\n    }\n    result = pow(mu,K)*exp(-mu)/denom;\n  }\n  return(result);\n}\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Sign fucntion\nint Sign(double x){\n  int result;\n  if( x < 0 ){ result = -1; }else{\n    if( x > 0 ){ result = 1; }else{\n      result = 0;\n    }}\n  \n  return(result);\n}\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Summary statistics for Ising model\nint Energy(mat X){\n  int nrow = X.n_rows, ncol = X.n_cols, s1 = 0, s2 = 0;\n  int result;\n  \n  for(int i = 0; i< nrow-1; i++){\n    s1 = s1 + accu( X.row(i)%X.row(i+1) );\n  }\n  for(int j = 0; j< ncol-1; j++){\n    s2 = s2 + accu( X.col(j)%X.col(j+1) );\n  }\n  \n  result = s1 + s2;\n  \n  return(result);\n}\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Perfect sampling\nmat ProppWilson(int nrow, int ncol, double b){\n  mat Xmin = -1*ones(nrow,ncol), Xmax = ones(nrow,ncol);\n  mat work1 = Xmin, work2 = Xmax;\n  work1.insert_cols(0,zeros(nrow));\n  work1.insert_cols(ncol+1,zeros(nrow));\n  work1.insert_rows(0,trans(zeros(ncol+2)));\n  work1.insert_rows(nrow+1,trans(zeros(ncol+2)));\n  work2.insert_cols(0,zeros(nrow));\n  work2.insert_cols(ncol+1,zeros(nrow));\n  work2.insert_rows(0,trans(zeros(ncol+2)));\n  work2.insert_rows(nrow+1,trans(zeros(ncol+2)));\t\n  int Time = 1; \n  \n  // until Xmin == Xmax  \n  while(  accu(abs(Xmax-Xmin)) > 0  ){    \t\n    Time = 2*Time;\n    for(int k = 0; k< Time; k++){\n      // just one component random scan update\n      int i = ceil(nrow*randu());   \n      int j = ceil(ncol*randu());      \n      double u  = randu();\t\t\n      // update for Xmin\n      double r1 = exp( 2*b*( work1(i,j-1)+work1(i,j+1)+work1(i-1,j)+work1(i+1,j) ) );\n      double p1 = r1/(1+r1);                \n      if( u < p1  ){\n        Xmin( (i-1),(j-1) ) = 1;\n        work1(i,j) = 1;\n      }else{\n        Xmin( (i-1),(j-1) ) = -1;\t\n        work1(i,j) = -1;\n      }\n      // update for Xmax\n      double r2 = exp( 2*b*( work2(i,j-1)+work2(i,j+1)+work2(i-1,j)+work2(i+1,j) ) );\n      double p2 = r2/(1+r2);  \n      if( u < p2  ){\n        Xmax( (i-1),(j-1) ) = 1;\n        work2(i,j) = 1;\n      }else{\n        Xmax( (i-1),(j-1) ) = -1;\t\n        work2(i,j) = -1;\n      }\n    } \n    \n  }\n  \n  return(Xmin);\n} \n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// random scan gibbs update\nmat Gibb(mat initial, double b, double cycle){\n  int nrow = initial.n_rows, ncol = initial.n_cols;\n  mat work = initial;\t\t\t\n  work.insert_cols(0,zeros(nrow));\n  work.insert_cols(ncol+1,zeros(nrow));\n  work.insert_rows(0,trans(zeros(ncol+2)));\n  work.insert_rows(nrow+1,trans(zeros(ncol+2)));\n  int iestop = cycle*nrow*ncol;\n  \n  for(int k = 0; k< iestop; k++){\n    \n    int i = ceil(nrow*randu());   \n    int j = ceil(ncol*randu());  \n    \n    double r = exp( 2*b*( work(i,j-1)+work(i,j+1)+work(i-1,j)+work(i+1,j) ) );\n    double p = r/(1+r);                  \n    if( randu() < p  ){\n      initial( (i-1),(j-1) ) = 1;\n      work(i,j) = 1;\n    }else{\n      initial( (i-1),(j-1) ) = -1;\t\n      work(i,j) = -1;\n    }\n  }\n  \n  return(initial);\t\n}\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// MH random scan update \nmat MH(mat initial, double b, double cycle){\n  int nrow = initial.n_rows, ncol = initial.n_cols;\n  mat work = initial;\n  work.insert_cols(0,zeros(nrow));\n  work.insert_cols(ncol+1,zeros(nrow));\n  work.insert_rows(0,trans(zeros(ncol+2)));\n  work.insert_rows(nrow+1,trans(zeros(ncol+2)));\n  int iestop = cycle*nrow*ncol;\n  \n  for(int k = 0; k< iestop; k++){\n    int i = ceil(nrow*randu());   \n    int j = ceil(ncol*randu());  \n    double p = exp( -2*b*work(i,j)*(work(i,j-1)+work(i,j+1)+work(i-1,j)+work(i+1,j)) );\n    \n    if( randu() < p  ){\n      initial( (i-1),(j-1) ) = -initial( (i-1),(j-1) );\n      work(i,j) = -work(i,j) ;\n    }else{\n      initial( (i-1),(j-1) ) = initial( (i-1),(j-1) );\t\n      work(i,j) = work(i,j);\n    }\t\n  }  \n  \n  return(initial);\t\n}\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Pseudo likelihood mcmc for Ising model example\nvec IsingPseudoMCMC(int outer, double initial, double sigma, mat X){\n  vec parameter(outer);\n  parameter(0) = initial;\n  double logprob,u,bprop;\n  double negativeInf = -std::numeric_limits<float>::infinity();;\t \n  int nrow = X.n_rows, ncol = X.n_cols;\n  mat work = X;\n  work.insert_cols(0,zeros(nrow));\n  work.insert_cols(ncol+1,zeros(nrow));\n  work.insert_rows(0,trans(zeros(ncol+2)));\n  work.insert_rows(nrow+1,trans(zeros(ncol+2)));\n  \n  double loglike=0, loglikeproposed=0;\n  for(int i = 1; i< nrow+1; i++){\n    for(int j = 1; j< ncol+1; j++){\n      double p = exp( 2*parameter(0)*(work(i,j-1)+work(i,j+1)+work(i-1,j)+work(i+1,j)) );\n      p = p/(1+p);\n      loglike = loglike + ((work(i,j)+1)/2)*log(p) + (1-(work(i,j)+1)/2)*log(1-p);\n    }\n  }\n  \n  // Start of MCMC Chain \n  for(int k = 0; k< outer-1; k++){\n    // propose parameters \n    bprop = parameter(k) + sigma*randn();\n    \n    if( bprop > 1 || bprop < 0 ){\n      logprob = negativeInf;\t\n    }else{\n      loglikeproposed = 0; \n      for(int i = 1; i< nrow+1; i++){\n        for(int j = 1; j< ncol+1; j++){\n          double p = exp( 2*bprop*(work(i,j-1)+work(i,j+1)+work(i-1,j)+work(i+1,j)) );\n          p = p/(1+p);\n          loglikeproposed = loglikeproposed + ((work(i,j)+1)/2)*log(p) + (1-(work(i,j)+1)/2)*log(1-p);\n        }\n      } \n      logprob = loglikeproposed - loglike;  \n    }\n    u = log( randu() );\n    if( u< logprob ){\n      parameter(k+1) = bprop;\n      loglike = loglikeproposed;\n    }else{\n      parameter(k+1) = parameter(k);\n      loglike = loglike;\n    } \n    \n  }  \n  \n  return(parameter);\n}\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Moller's auxiliary variable algorithm for Ising model\nvec IsingMoller(int outer, double initial, double sigma, mat X){\n  vec parameter(outer);\n  parameter(0) = initial;\n  double logprob,u,bprop;\n  double negativeInf = -std::numeric_limits<float>::infinity();;\t\n  int nrow = X.n_rows, ncol = X.n_cols;\n  \n  // auxiliary variable \n  mat Y = ProppWilson(nrow,ncol,initial); \n  int XStat = Energy(X), YStat = Energy(Y);\n  \n  // Start of MCMC Chain \n  for(int k = 0; k< outer-1; k++){\n    // propose parameters \n    bprop = parameter(k) + sigma*randn();\n    // propose auxiliary variables \n    mat Yprop = ProppWilson(nrow,ncol,bprop);\n    int YpropStat = Energy(Yprop);\n    \n    if( bprop > 1 || bprop < 0 ){\n      logprob = negativeInf;\t\n    }else{\n      \n      logprob = \n        ( initial*YpropStat + bprop*XStat + parameter(k)*YStat ) -\n        ( initial*YStat + parameter(k)*XStat + bprop*YpropStat );\n    }\n    \n    u = log( randu() );\n    if( u< logprob ){\n      parameter(k+1) = bprop;\n      YStat = YpropStat;\n    }else{\n      parameter(k+1) = parameter(k);\n      YStat = YStat;\n    } \n    \n  }  \n  \n  return(parameter);\n}\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Exchange algorithm for Ising model\nvec IsingExchange(int outer, double initial,double sigma, mat X){\n  vec parameter(outer);\n  parameter(0) = initial;\n  double logprob,u,bprop;\n  double negativeInf = -std::numeric_limits<float>::infinity();;\t\n  int nrow = X.n_rows, ncol = X.n_cols;\n  int XStat = Energy(X), YStat;\n  mat Y(nrow,ncol); // auxiliary variable\n  \n  // Start of MCMC Chain \n  for(int k = 0; k< outer-1; k++){\n    // propose parameters \n    bprop = parameter(k) + sigma*randn();\n    // propose auxiliary variables \n    Y = ProppWilson(nrow,ncol,bprop);\n    YStat = Energy(Y);\n    \n    if( bprop > 1 || bprop < 0 ){\n      logprob = negativeInf;\t\n    }else{\n      logprob = ( bprop-parameter(k) )*XStat +   ( parameter(k)-bprop )*YStat;\n    }\n    u = log( randu() );\n    if( u< logprob ){\n      parameter(k+1) = bprop;\n    }else{\n      parameter(k+1) = parameter(k);\n    } \n    \n  }  \n  \n  return(parameter);\n}\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Double Metropolis Hastings for Ising model\nvec IsingDMH(int outer, int inner, double initial, double sigma, mat X){\n  vec parameter(outer);\n  parameter(0) = initial;\n  double logprob,u,bprop;\n  double negativeInf = -std::numeric_limits<float>::infinity();;\t\n  int nrow = X.n_rows, ncol = X.n_cols;\n  int XStat = Energy(X), YStat;\n  mat Y(nrow,ncol); // auxiliary variable\n  \n  // Start of MCMC Chain \n  for(int k = 0; k< outer-1; k++){\n    // propose parameters \n    bprop = parameter(k) + sigma*randn();\n    // propose auxiliary variables \n    Y = Gibb(X,bprop,inner);\n    YStat = Energy(Y);\n    \n    if( bprop > 1 || bprop < 0 ){\n      logprob = negativeInf;\t\n    }else{\n      logprob = ( bprop-parameter(k) )*XStat + ( parameter(k)-bprop )*YStat;\n    }\n    u = log( randu() );\n    if( u< logprob ){\n      parameter(k+1) = bprop;\n    }else{\n      parameter(k+1) = parameter(k);\n    } \n    \n  }  \n  \n  return(parameter);\n}\n\n\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Atchade's adpative algorithm for Ising model\nvec IsingAtchade(int outer, int inner, double initial, double sigma, vec th, mat X){\t    \n  int d = th.n_rows, Vmin;\n  vec Vis= zeros(d), gamVec(4), cVec;    // gamVec length and sequence both can be changed \n  for(int i = 0; i< 4; i++){ gamVec[i] = pow( 0.1, i ); }\n  \n  vec parameter(outer); \n  mat Data = X;\n  int Stat0 = Energy(X), Stat;\n  parameter(0) = initial;\n  mat Esum = zeros(outer,d); // summary statistics will be stored\n  \n  // approximate cVec ( logZ(theta_{i}) ) until gam is small\n  for(int igam = 0; igam< 4; igam++){  \n    \n    if( igam == 3 ){ Vmin=1000; }else{ Vmin=0; } //Vmin=1000 can be changed\n    double gam = gamVec(igam);\n    X = Data, Stat = Stat0; \n    vec VisTemp = zeros(d);     \n    \n    // pos denotes the variable I in Algorithm 2.1\n    int pos = d-1;                          \n    \n    // cVec is the variable c in Algorithm 2.1\n    if( igam == 0 ){ cVec = zeros(d); }\n    \n    // Stopping criteria\n    while( VisTemp.min() <= Vmin || abs(  VisTemp-mean(VisTemp)*ones(d)  ).max() >= 0.2*mean(VisTemp) ){\n      // Update X_{n}\n      X = MH(X, th(pos), inner);\n      Stat = Energy(X);\n      \n      // Update I; meaning pos\n      double mx = (th*Stat - cVec).max();\n      vec A = exp((th*Stat - cVec - mx)) / sum( exp((th*Stat - cVec - mx))\t);\n      double u = randu(), l = -1, om = 0;\n      while( om<u ){\n        l = l+1;\n        om = om +A[l];\n      }\n      pos = l;\n      \n      // Update c\n      cVec = cVec + log(1+gam)*A;\n      \n      // We need the next two updates to control the sequence gamma\n      VisTemp[pos] = VisTemp[pos] + 1; \t\t\n      //if( igam ==3 ){\t\t\n      //Vis[pos] = Vis[pos] + 1;\n      //Esum(Vis[pos]-1,pos) = Stat; \t\t\t\n      //}\n      \n    }\n  }  \n  \n  // We are now ready the start the MCMC\n  // From here, gamma is deterministic small value (0.001) \n  // Initilization of ${theta_n},X,I,c$    \n  double theta, thetaprop;\n  theta =  parameter(0);\n  X = Data, Stat = Stat0;\n  int pos = d-1;    \n  double gam = gamVec(3),prob; \n  \n  // Proposal Parameters\n  double b = -1.5, Acc = 0, tau = 0.3;\n  \n  // c = cVec from above iteration\n  // Bandwidth for smoothing the estimate\n  int hpar = 10;\n  for(int k = 0; k< outer-1; k++){\n    \n    // Update X_{n}\n    X = MH(X, th(pos), inner);\n    Stat = Energy(X);\n    \n    // Update I; meaning pos\n    double mx = (Stat*th - cVec).max();\n    vec A = exp((Stat*th - cVec - mx)) / sum( exp((Stat*th - cVec - mx))\t);\n    double u = randu(), l = -1, om = 0;\n    while( om<u ){\n      l = l+1;\n      om = om +A[l];\n    }\n    pos = l;\n    \n    // Update c\n    cVec = cVec + log(1+gam)*A;\n    Vis[pos] = Vis[pos] + 1;\n    Esum(Vis[pos]-1,pos) = Stat; \n    \n    // Update theta if there are enough observations\n    // Evaluate \\pi(theta)\n    // Distance to each theta^i\n    uvec ind = sort_index(  abs( theta*ones(d) - th )    );   \t\n    vec cw = (1/hpar)*ones(hpar);\n    \n    // There might be some trouble here if none of the closest 'hpar'\n    // particles around thetaprop has received data\n    vec expEtheta = zeros(hpar);\n    for(int i = 0; i< hpar; i++){\t\n      if( Vis[ind[i]] == 0 ){ expEtheta[i] = 0; }else{     \n        vec tmp = ( theta - th[ind[i]] )*Esum.col( ind[i] ) ;\t\n        tmp = tmp(  span( 0, Vis[ind[i]]-1 )  );\n        double tmpMax = tmp.max();\t\n        expEtheta[i] = tmpMax + log( sum( exp( tmp - tmpMax ) ) ) - log( Vis[ind[i]] ); // eq(8)'s [   ] part       \t\n      }\n    }\n    vec dummy2(hpar);\n    for(int i = 0; i< hpar; i++){ dummy2[i] = cVec[ ind( span(0,hpar-1) )[i] ] + expEtheta[i] + cw[i];\t}\n    double ftheta = dummy2.max();                        \n    // Eth = log(exp(E(x,theta))) - log(Z(theta)) \n    // Stat0*theta: log(exp(E(x,theta)))= E(x,theta)\n    // log(sum( exp(cVec[ind[1:hpar]]+expEtheta+cw) )): log(Z(theta))  \n    double Eth = Stat0*theta - ftheta - log(sum( exp(dummy2 - ftheta) ));\n    \n    // Propose a new theta\n    thetaprop = theta + sigma*randn();\n    if( thetaprop > 1 || thetaprop < 0 ){ prob = 0; }else{\n      \n      // Evaluate posterior at the new theta        \n      ind = sort_index(  abs( thetaprop*ones(d) - th )    );   \t\n      cw = (1/hpar)*ones(hpar);\n      \n      // There might be some trouble here if none of the closest 'hpar'\n      // particles around thetaprop has received data\n      vec expEthetaprop = zeros(hpar);        \n      for(int i = 0; i< hpar; i++){\t\n        if( Vis[ind[i]] == 0 ){ expEthetaprop[i] = 0; }else{\n          vec tmp = ( thetaprop - th[ind[i]] )*Esum.col( ind[i] ) ;\t\n          tmp = tmp(  span( 0, Vis[ind[i]]-1 )  );\n          double tmpMax = tmp.max();\t\n          expEthetaprop[i] = tmpMax + log( sum( exp( tmp - tmpMax ) ) ) - log( Vis[ind[i]] ); // eq(8)'s [   ] part       \t\n        }\n      }\n      for(int i = 0; i< hpar; i++){ dummy2[i] = cVec[ ind( span(0,hpar-1) )[i] ] + expEthetaprop[i] + cw[i];\t}\n      double fthetaprop = dummy2.max();   \n      double Ethprop = Stat0*thetaprop - fthetaprop - log(sum( exp(dummy2 - fthetaprop) ));\t\t\t\t\t\t\n      \n      // Acceptance prob.\n      prob = exp(Ethprop-Eth);\n    }\n    // Accept - Reject\n    u = randu();\n    if(u <= prob){ theta = thetaprop; }\n    \n    // Adaptive scaling of the proposal\n    vec MIN(2);\n    MIN[0] = 1, MIN[1] = prob;\n    Acc = Acc + (1/(k+1))*( MIN.min() - Acc ); \n    b = b +(1/(k+1))*( MIN.min() - tau );\n    \n    // Save output\n    parameter(k+1) = theta;\n  }\n  \n  \n  \n  return(parameter);\n}\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Anealed importance sampling logZ estimate for nrow by ncol Ising model\ndouble logZAIS(int noImp, int noTemp, double b, int nrow, int ncol){\n  // noImp - number of importance samples\n  // a and b - Ising params\n  // importance samples done in parallel\n  \n  // temperature schedule\n  vec beta = linspace<vec>(0, 1, noTemp+1);\n  vec logweight(noImp);\n  \n  int M;\n#pragma omp parallel shared(logweight) private(M)\n{\t\n#pragma omp for schedule(static)  \n  for(M = 0; M< noImp; M++){\n    \n    // sample random grid \n    mat y = sign(randn(nrow,ncol));\n    mat work = y;\t\t\t\n    work.insert_cols(0,zeros(nrow));\n    work.insert_cols(ncol+1,zeros(nrow));\n    work.insert_rows(0,trans(zeros(ncol+2)));\n    work.insert_rows(nrow+1,trans(zeros(ncol+2)));\n    \n    int Stat = Energy(y);\n    double logw = (beta[1]-beta[0])*b*Stat - (beta[0]-beta[1])*(nrow*ncol)*log(2);\n    \n    // sample from succesive tempered distributions and calc weight\n    for(int n = 1; n< noTemp; n++){\n      // random scan Gibbs sampler\n      // choose one spin in each grid to update\n      int i = ceil(nrow*randu());   \n      int j = ceil(ncol*randu());   \t   \n      double r = exp( 2*beta[n]*b*( work(i,j-1)+work(i,j+1)+work(i-1,j)+work(i+1,j) ) );\n      double p = r/(1+r); \n      \n      if( randu() < p  ){\n        y( (i-1),(j-1) ) = 1;\n        work(i,j) = 1;\n      }else{\n        y( (i-1),(j-1) ) = -1;\t\n        work(i,j) = -1;\n      }\n      // calc AIS weight in log space\n      Stat = Energy(y);\n      logw = logw + (beta[n+1]-beta[n])*b*Stat - (beta[n]-beta[n+1])*(nrow*ncol)*log(2);\n    }\n    logweight[M] = logw;     \n  }\n}\n\ndouble mx = logweight.max();\ndouble logZ = log(mean(exp(logweight - mx))) + mx; \t\nreturn(logZ);\n}\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Playing Russian Roulette\nList Roulette(int nrow, int ncol, double logZtilde, int NimpSamps, double bprop, double r, double cx, int cmax, int ru, double mu, int NTemp){\n  double series, term, weight, maxk, Corr;\n  int count, k;\n  vec logZx, kappa, q;\n  \n  if( ru == 1 ){\n    // use roulette truncation\n    while( ru == 1 ){\n      count = 1, series = 1, term = 1, weight = 1;\n      logZx = zeros(cmax), kappa = zeros(cmax), q = zeros(cmax);\n      while( count < cmax ){\n        \n        // calculate estimate of Z and kappa\n        logZx[count-1] = logZAIS(NimpSamps, NTemp, bprop, nrow,ncol);\n        kappa[count-1] = 1  -  cx * exp(logZx[count-1]-logZtilde);\n        \n        // if kappa is outside convergence region make c and r smaller\n        if( fabs(kappa[count-1]) > 1 ){ break; }\t\t\t  \t\n        term = term*kappa[count-1];\n        \n        if( fabs(term) < r ){\n          // play Roulette\n          q[count-1] = fabs(term)/r;\n          weight = weight*q[count-1];    \n          if( q[count-1] > randu() ){\n            // survivie\n            count = count + 1;\n            series = series + (term/weight);\t\n          }else{\n            // terminate\n            maxk = count - 1; \n            ru = 0;\n            break;}}else{\n              // add to go to the next term\n              series = series + term;\n              count = count + 1; \n            }\n            \n      } // end of while (count < cmax)\n      \n      // leave while loop if cmax exceeded or roulette terminated\n      if( count >= cmax || ru == 0 ){ break; }else{\n        // otherwise make c smaller to ensure convergence    \n        cx = cx*0.9;\n        r = 1-cx;\n        // In R, remove logZx, kappa, q at here\n      }  \n    } // end of while(ru == 1)   \n    \n    // if roulette terminated in time\n    if( count < cmax ){ Corr = series; }else{\t\n      maxk = cmax;\n      // use poisson truncation, Corr is calculated through inverse of poisson density;\n      k = rPois(mu);\n      if( k == 0 ){ Corr = 1/dPois(k,mu); }else{\n        while( ru == 0 ){\n          kappa = zeros(k), logZx = zeros(k);\n          for(int ii = 0; ii < k; ii++){\n            logZx[ii] = logZAIS(NimpSamps, NTemp, bprop, nrow,ncol);\n            kappa[ii] = 1  -  cx * exp(logZx[ii]-logZtilde);     \t \t   \t\n            if( ( ii == k) && ( fabs(kappa[ii]) < 1 ) ){ ru = 1; } \n            if( fabs(kappa[ii]) > 1 ){\n              cx = cx*0.9;\n              // In R, remove logZx, kappa at here\n              break;\n            }\n          }\n        } // end of while( ru == 0 )\n        \n        Corr = prod(kappa)/dPois(k,mu);  \n      }  \n    }\n  }else{\n    // use poisson truncation\n    k = rPois(mu);\n    maxk = k;\n    if( k == 0 ){ Corr = 1/dPois(k,mu); }else{      \t\n      while( ru == 0 ){\n        kappa = zeros(k), logZx = zeros(k); \n        for(int ii = 0; ii < k; ii++){       \n          logZx[ii] = logZAIS(NimpSamps, NTemp, bprop, nrow,ncol);\n          kappa[ii] = 1  -  cx * exp(logZx[ii]-logZtilde);     \t \n          if( ( ii == k) && ( fabs(kappa[ii]) < 1 ) ){ ru = 1; } \n          if( fabs(kappa[ii]) > 1 ){\n            cx = cx*0.9;\n            // In R, remove logZx, kappa at here\n            break;\n          }\n        }\n      } // end of while( ru == 0 )\n      \n      Corr = prod(kappa)/dPois(k,mu);  \n    } \n  }\n  \n  return List::create(Named(\"Corr\") = Corr, Named(\"c\") = cx, Named(\"maxk\") = maxk);\t\n}\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Russian Roulette for Ising model\nmat IsingRoulette(int outer, int NimpSamps, int Ntemp, double initial, double sigma, double r, double cx, int cmax, int ru, double mu, mat X){\n  int nrow = X.n_rows, ncol = X.n_cols, Stat = Energy(X), sCorrprop;\n  double lhX, lhXp, logZtilde, logprob,u,bprop, Corr, c, maxk;\n  double negativeInf = -std::numeric_limits<float>::infinity();;;\n  \n  \n  // posterior sample, sign will be stored. \n  mat parameter(2,outer); \n  // initial values\n  parameter(0,0) = initial, parameter(1,0) = 1;\n  \n  // current log likelihood\n  logZtilde = logZAIS(NimpSamps, Ntemp, parameter(0,0), nrow, ncol);\n  lhX = parameter(0,0)*Stat + log(cx) - logZtilde;\n  \n  // MCMC chain \n  for(int k = 0; k< outer-1; k++){\n    \n    // propose parameters \n    bprop = parameter(0,k) + sigma*randn();  \n    if( bprop > 1 || bprop < 0 ){ logprob = negativeInf; }else{\n      \n      // calculate log Z_tilde using extra importance samples\n      logZtilde = logZAIS(2*NimpSamps, Ntemp, bprop, nrow, ncol);\n      \n      // calculate correction  \n      List output = Roulette(nrow, ncol, logZtilde, NimpSamps, bprop, r, cx, cmax, ru, mu, Ntemp);\n      vec output1 = output[0], output2 = output[1], output3 = output[2];\n      Corr = output1[0], c = output2[0], maxk = output3[0];\n      sCorrprop = Sign(Corr);\n      \n      // calculate estimated likelihood in log-space\n      lhXp = bprop*Stat + log(c) + log(fabs(Corr)) - logZtilde;\n      // calculate MH ratio\n      logprob = lhXp - lhX;\n    }\n    u = log( randu() );\n    if( u < logprob ){\n      parameter(0,k+1) = bprop;\n      parameter(1,k+1) = sCorrprop;\n      lhX = lhXp;\n    }else{\n      parameter(0,k+1) = parameter(0,k);\n      parameter(1,k+1) = parameter(1,k);\n      lhX = lhX;\n    }\n  }\n  \n  \n  return(parameter);\n}\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Noisy Exchange algorithm for Ising model\nvec IsingNExchange(int outer, int NimpSamps, double initial, double sigma, mat X){\n  vec parameter(outer), logweight(NimpSamps);\n  parameter(0) = initial;\n  double logprob,u,bprop, mx, logRatio;\n  double negativeInf = -std::numeric_limits<float>::infinity();;\t\n  int nrow = X.n_rows, ncol = X.n_cols;\n  int XStat = Energy(X);\n  \n  \n  // Start of MCMC chain \n  for(int k = 0; k< outer-1; k++){\n    // propose parameters \n    bprop = parameter(k) + sigma*randn();\n    if( bprop > 1 || bprop < 0 ){ logprob = negativeInf; }else{\n      \n      int M;\n#pragma omp parallel shared(logweight) private(M)\n{\t\n#pragma omp for schedule(static)  \n  for(M = 0; M< NimpSamps; M++){\n    mat Y = ProppWilson(nrow,ncol,bprop); // auxiliary variable\n    logweight[M] = ( parameter(k)-bprop )*Energy(Y);\n  }\n} // End of parallelization       \n\nmx = logweight.max();\nlogRatio = log(mean(exp(logweight - mx))) + mx; \t\nlogprob = ( bprop-parameter(k) )*XStat + logRatio;\n    }\n    u = log( randu() );\n    if( u< logprob ){\n      parameter(k+1) = bprop;\n    }else{\n      parameter(k+1) = parameter(k);\n    }\n    \n  }\n  \n  return(parameter);\n}\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Noisy DMH algorithm for Ising model\nvec IsingNDMH(int outer, int inner, int NimpSamps, double initial, double sigma, mat X, int num){\n  vec parameter(outer), logweight(NimpSamps);\n  parameter(0) = initial;\n  double logprob,u,bprop, mx, logRatio;\n  double negativeInf = -std::numeric_limits<float>::infinity();;\t\n  int XStat = Energy(X);\n  omp_set_num_threads(num);\n  \n  \n  // Start of MCMC chain \n  for(int k = 0; k< outer-1; k++){\n    // propose parameters \n    bprop = parameter(k) + sigma*randn();\n    if( bprop > 1 || bprop < 0 ){ logprob = negativeInf; }else{\n      \n      int M;\n#pragma omp parallel shared(logweight) private(M)\n{\t\n#pragma omp for schedule(static)  \n  for(M = 0; M< NimpSamps; M++){\n    mat Y = Gibb(X,bprop,inner);  // auxiliary variable\n    logweight[M] = ( parameter(k)-bprop )*Energy(Y);\n  }\n} // End of parallelization       \n\nmx = logweight.max();\nlogRatio = log(mean(exp(logweight - mx))) + mx; \t\nlogprob = ( bprop-parameter(k) )*XStat + logRatio;\n    }\n    u = log( randu() );\n    if( u< logprob ){\n      parameter(k+1) = bprop;\n    }else{\n      parameter(k+1) = parameter(k);\n    }\n    \n  }\n  \n  return(parameter);\n}\n\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Count visitation for Atchade's adpative algorithm\nvec StopAtchade(int inner, vec th, mat X){\t    \n  int d = th.n_rows, Vmin;\n  vec Vis= zeros(d), VisTemp = zeros(d), gamVec(4), cVec;    // gamVec length and sequence both can be changed \n  for(int i = 0; i< 4; i++){ gamVec[i] = pow( 0.1, i ); }\n  \n  mat Data = X;\n  int Stat0 = Energy(X), Stat;\n  \n  // approximate cVec ( logZ(theta_{i}) ) until gam is small\n  for(int igam = 0; igam< 4; igam++){  \n    \n    if( igam == 3 ){ Vmin=1000; }else{ Vmin=0; } //Vmin=1000 can be changed\n    double gam = gamVec(igam);\n    X = Data, Stat = Stat0; \n    VisTemp = zeros(d);     \n    \n    // pos denotes the variable I in Algorithm 2.1\n    int pos = d-1;                          \n    \n    // cVec is the variable c in Algorithm 2.1\n    if( igam == 0 ){ cVec = zeros(d); }\n    \n    // Stopping criteria\n    while( VisTemp.min() <= Vmin || abs(  VisTemp-mean(VisTemp)*ones(d)  ).max() >= 0.2*mean(VisTemp) ){\n      // Update X_{n}\n      X = MH(X, th(pos), inner);\n      Stat = Energy(X);\n      \n      // Update I; meaning pos\n      double mx = (th*Stat - cVec).max();\n      vec A = exp((th*Stat - cVec - mx)) / sum( exp((th*Stat - cVec - mx))\t);\n      double u = randu(), l = -1, om = 0;\n      while( om<u ){\n        l = l+1;\n        om = om +A[l];\n      }\n      pos = l;\n      \n      // Update c\n      cVec = cVec + log(1+gam)*A;\t\n      \n      // We need the next two updates to control the sequence gamma\n      VisTemp[pos] = VisTemp[pos] + 1; \t\t\n      //if( igam ==3 ){\t\t\n      //Vis[pos] = Vis[pos] + 1;\n      //Esum(Vis[pos]-1,pos) = Stat; \t\t\t\n      //}\n      \n    }\n    Vis = Vis + VisTemp;\n  }\n  return(Vis);\n}\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\nvec IsingFDMH(int outer, int inner, double initial, double sigma, mat X){\n  vec parameter(outer);\n  parameter(0) = initial;\n  double logprob,u,bprop;\n  double negativeInf = -std::numeric_limits<float>::infinity();; \n  int nrow = X.n_rows, ncol = X.n_cols;\n  int XStat = Energy(X), YStat;\n  mat Y(nrow,ncol); // auxiliary variable\n  \n  // Start of MCMC Chain \n  for(int k = 0; k< outer-1; k++){\n    // propose parameters \n    bprop = parameter(k) + sigma*randn();\n    // propose auxiliary variables \n    Y = Gibb(X,bprop,inner);\n    YStat = Energy(Y);\n    \n    if( bprop > 1 || bprop < 0 ){\n      logprob = negativeInf; \n    }else{\n      logprob = ( bprop-parameter(k) )*XStat + ( parameter(k)-bprop )*YStat;\n      logprob = 0.5*logprob;\n    }\n    u = log( randu() );\n    if( u< logprob ){\n      parameter(k+1) = bprop;\n    }else{\n      parameter(k+1) = parameter(k);\n    }    \n  }  \n  \n  return(parameter);\n}\n\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// AEX for Ising model\nList IsingAEX(int Niter, int Numaux, double cycle, double t0, int neighbor, vec th, mat thdist, double initial, double sigma, mat X){ \n  \n  int auxNiter = Numaux*20 + Numaux;\n  double d = th.n_rows;                                        // number of particles\n  vec p = (1/d)*ones(d), lw = zeros(d), Vis = zeros(d);        // target prob, logartihm of abundance factor\n  mat  Sdummy = zeros(auxNiter,3);                                  // data base suff, parameter, abundance factor will be stored\n  \n  // initialize\n  int indprop, ind = 0;\n  Sdummy(0,2) = lw[ind], Sdummy(0,1) = th[ind];\n  mat auxvar = Gibb(X, Sdummy(0,1), cycle);\n  Sdummy(0,0) = Energy( auxvar );\n  \n  // preliminary run of the auxiliary chain \n  for(int k = 0; k< auxNiter-1; k++){\n    // decide update theta or aux var \n    if( randu() < 0.75 ){  // update theta\n      uvec dummy = sort_index(  thdist.row( ind )   );  // using distance matrix, ordering from current theta \n      uvec samplist = dummy( span( 1, neighbor )  );    // neighborhood calcul\n      int ii  = floor( (neighbor)*randu() ) ;         // sample uniformly from neighborhood  \n      indprop = samplist[ii];\n      \n      double thprop = th[indprop];\n      Sdummy(k+1,0) = Sdummy(k,0);\n      double logprob = lw[ind] - lw[indprop]  + Sdummy(k,0)*( thprop-Sdummy(k,1) ); \n      \n      double u = log( randu() );\n      if( u< logprob ){\n        Sdummy(k+1,1) = thprop;\n        ind = indprop;\n      }else{\n        Sdummy(k+1,1) = Sdummy(k,1);\n        ind = ind; \n      }  \n      \n    }else{                 // update aux var, always accept by DBE\n      auxvar = Gibb(auxvar, Sdummy(k,1), cycle);\n      ind = ind, Sdummy(k+1,1) = Sdummy(k,1); Sdummy(k+1,0) = Energy(auxvar);\n    }\n    \n    // update abundance factor\n    vec e = zeros(d);\n    e[ind] = 1;\n    double val;\n    double kdummy = k;\n    if( t0 > kdummy ){ val = t0; }else{ val = kdummy; }\n    lw = lw + (t0/val)*(e-p);\n    Sdummy(k+1,2) = lw[ind];\n    \n    // record visitation frequencies\n    Vis = Vis + e;\n  }  \n  \n  // burn in Numaux number and equally 20 sample spaced\n  mat S = zeros(Numaux+Niter,3); \n  for(int k = 0; k< Numaux; k++){\n    S(k,0) = Sdummy(Numaux-1 + (k+1)*20, 0);   \n    S(k,1) = Sdummy(Numaux-1 + (k+1)*20, 1);\n    S(k,2) = Sdummy(Numaux-1 + (k+1)*20, 2);\n  }\n  \n  \n  // initialize final chain\n  vec parameter(Niter);\n  parameter(0) = initial;\n  double negativeInf = -std::numeric_limits<float>::infinity();; \n  int XStat = Energy(X);\n  double logprob;\n  \n  // run auxiliary chain and target chain simultaneously\n  for(int k = 0; k< Niter-1; k++){\n    \n    // Auxiliary chain \n    // decide update theta or aux var \n    if( randu() < 0.75 ){  // update theta\n      uvec dummy = sort_index(  thdist.row( ind )   );  // using distance matrix, ordering from current theta \n      uvec samplist = dummy( span( 1, neighbor )  );    // neighborhood calcul\n      int ii  = floor( (neighbor)*randu() ) ;         // sample uniformly from neighborhood  \n      indprop = samplist[ii];\n      \n      double thprop = th[indprop];\n      S(Numaux-1 + k + 1, 0) = S(Numaux-1 + k,0);\n      double logprob1 = lw[ind] - lw[indprop]  + S(Numaux-1 + k,0)*( thprop-S(Numaux-1 + k,1) ); \n      \n      double u = log( randu() );\n      if( u< logprob1 ){\n        S(Numaux-1 + k + 1, 1) = thprop;\n        ind = indprop;\n      }else{\n        S(Numaux-1 + k + 1, 1) = S(Numaux-1 + k, 1);\n        ind = ind; \n      } \n    }else{                 // update aux var, always accept by DBE\n      auxvar = Gibb(auxvar, S(Numaux-1 + k, 1), cycle);\n      ind = ind, S(Numaux-1 + k + 1, 1) = S(Numaux-1 + k, 1); S(Numaux-1 + k + 1, 0) = Energy(auxvar);\n    }\n    \n    // update abundance factor\n    vec e = zeros(d);\n    e[ind] = 1;\n    double val;\n    double kdummy = auxNiter-1 + k;\n    if( t0 > kdummy ){ val = t0; }else{ val = kdummy; }\n    lw = lw + (t0/val)*(e-p);\n    S(Numaux-1 + k + 1, 2) = lw[ind];\n    \n    \n    // Target chain\n    double bprop = parameter(k) + sigma*randn();   \n    if( bprop > 1 || bprop < 0 ){\n      logprob = negativeInf; \n    }else{\n      \n      vec Prob = zeros(Numaux + k + 1);  // because the number of row of S is Numaux + k + 1\n      for(int m = 0; m< Numaux + k + 1; m++){\n        Prob[m] =  S(m,2) + S(m,0)*(bprop-S(m,1)); \n      }\n      \n      double mx = (  Prob  ).max();\n      Prob = exp(Prob - mx);                    \n      Prob = Prob/sum(Prob);     \n      double uu = randu(), l = -1, om = 0;\n      while( om<uu ){\n        l = l+1;\n        om = om + Prob[l];\n      } \n      int Statprop = S(l,0);\n      logprob = ( bprop-parameter(k) )*XStat + ( parameter(k)-bprop )*Statprop;\n    }\n    \n    if( log( randu() )< logprob ){\n      parameter(k+1) = bprop;\n    }else{\n      parameter(k+1) = parameter(k);\n    }     \n  }  \n  \n  \n  return List::create(Named(\"Vis\") = Vis, Named(\"S\") = S, Named(\"abundance\") = lw, Named(\"par\") = parameter); \n}\n\n\n\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Summary Statictics of simulated datas in Parallel\nvec pAuxStatPerf(int nrow, int ncol, double b, int m, int num){\n  vec H(m);                       \n  omp_set_num_threads(num);\n  \n  int M;\n#pragma omp parallel shared(b) private(M)\n{\t\n#pragma omp for schedule(static)  \n  for(M = 0; M < m; M++){\n    mat Y = ProppWilson(nrow, ncol, b);\n    double sumstat = Energy(Y);\n    H(M) = sumstat;\n  }\n}\nreturn(H);        \t\n}\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\n// Summary Statictic for Ising model in Parallel\nvec pAuxStatGibb(mat X, int cycle, double b, int m, int num){\n  vec H(m);                       \n  omp_set_num_threads(num);\n  \n  int M;\n#pragma omp parallel shared(b) private(M)\n{\t\n#pragma omp for schedule(static)  \n  for(M = 0; M < m; M++){\n    mat Y = Gibb(X, b, cycle);\n    double sumstat = Energy(Y);\n    H(M) = sumstat;\n  }\n}\nreturn(H);        \t\n}\n\n\n// [[Rcpp::depends(\"RcppArmadillo\")]]\n// [[Rcpp::export]]\nmat statGibb(mat initial, double b, double cycle){\n  int nrow = initial.n_rows, ncol = initial.n_cols;\n  mat work = initial;\n  work.insert_cols(0,zeros(nrow));\n  work.insert_cols(ncol+1,zeros(nrow));\n  work.insert_rows(0,trans(zeros(ncol+2)));\n  work.insert_rows(nrow+1,trans(zeros(ncol+2)));\n  int iestop = nrow*ncol;\n  vec Ystats(cycle);\n  \n  for(int m = 0; m < cycle; m++){\n    for(int k = 0; k< iestop; k++){\n      \n      int i = ceil(nrow*randu());\n      int j = ceil(ncol*randu());\n      \n      double r = exp( 2*b*( work(i,j-1)+work(i,j+1)+work(i-1,j)+work(i+1,j) ) );\n      double p = r/(1+r);\n      if( randu() < p  ){\n        initial( (i-1),(j-1) ) = 1;\n        work(i,j) = 1;\n      }else{\n        initial( (i-1),(j-1) ) = -1;\n        work(i,j) = -1;\n      }\n      \n    }\n    Ystats(m) = Energy(initial);\n  }\n\n  return(Ystats);\n}\n\n\n// [[Rcpp::export]]\nvec GPmcmcNorm(int Niter, vec theta, double sigma, double lZ, vec betahat, vec phihat, vec Designmat, vec y, double stat){\n  int thnrow = Designmat.n_rows;                                                \n  \n  double lZp = 0, logprob = 0, u = 0;                                               \n  double negativeInf = -std::numeric_limits<float>::infinity();;\t               \n  double phi1hat = phihat[0], sigmasqhat = phihat[1]; \n  \n  int percentile = 0.0025*thnrow; \n  \n  vec Domain(2);                                                         \n  vec dummy = sort( Designmat );\n  Domain(0) = dummy(percentile);\n  Domain(1) = dummy(thnrow-1-percentile);\n  \n  \n  mat h1(thnrow,thnrow);   \n  vec h1dcross(thnrow);     \n  \n  for(int i = 0; i < thnrow; i++){\n    for(int j = 0; j <= i; j++){\n      h1(i,j) = h1(j,i) = fabs(Designmat(i)-Designmat(j));\n    }\n  }\n  mat Sigma = sigmasqhat*(1+sqrt(3)*h1/phi1hat)%exp(-sqrt(3)*h1/phi1hat);\n  mat InvSigma = inv(Sigma);\t   \n  mat Xth = ones(thnrow,1);\n  Xth.insert_cols(1,Designmat);\t \n  \n  for(int k = 0; k< Niter; k++){\n    \n    if( (k > 1000) && (k <= 10000) ){\n      sigma = stddev(theta);\n    }\n    vec Znormal = randn(1);\n    vec thetaprev(1);\n    thetaprev[0] = theta[k];\n    \n    vec thetaprop = thetaprev + Znormal*sigma;\n    \n    if( thetaprop[0] > Domain[1] || thetaprop[0] < Domain[0] ){\n      logprob = negativeInf;\n      \n    }else{\n      for(int i = 0; i< thnrow; i++){\n        h1dcross[i] =  fabs(thetaprop[0]-Designmat(i));\n      }\n      mat Sigmacross = sigmasqhat*(1+sqrt(3)*h1dcross/phi1hat)%exp(-sqrt(3)*h1dcross/phi1hat);\n      vec xpoint = ones(1);\n      xpoint.insert_rows(1,thetaprop);\n      lZp = (trans(xpoint)*betahat + trans(Sigmacross)* InvSigma*(y-Xth*betahat))[0];\n      logprob = ((thetaprop - thetaprev)*stat + (lZ - lZp))[0];\n    }\n    \n    u = log( randu() );\n    if( u< logprob ){\n      theta.insert_rows(k+1,thetaprop);\n      lZ = lZp;\n    }else{\n      theta.insert_rows(k+1,thetaprev);\n    }\n    \n  }\n  \n  return theta;\n}\n\n\n\n// [[Rcpp::export]]\nvec GPmcmcLik(int Niter, vec theta, double sigma, double lhXZ, vec betahat, vec phihat, vec Designmat, vec y, double stat){\n  int thnrow = Designmat.n_rows;                                                \n  \n  double lhXZp = 0, logprob = 0, u = 0;                                               \n  double negativeInf = -std::numeric_limits<float>::infinity();;\t               \n  double phi1hat = phihat[0], sigmasqhat = phihat[1]; \n  \n  int percentile = 0.0025*thnrow; \n  \n  vec Domain(2);                                                         \n  vec dummy = sort( Designmat );\n  Domain(0) = dummy(percentile);\n  Domain(1) = dummy(thnrow-1-percentile);\n  \n  \n  mat h1(thnrow,thnrow);   \n  vec h1dcross(thnrow);     \n  \n  for(int i = 0; i < thnrow; i++){\n    for(int j = 0; j <= i; j++){\n      h1(i,j) = h1(j,i) = fabs(Designmat(i)-Designmat(j));\n    }\n  }\n  mat Sigma = sigmasqhat*(1+sqrt(3)*h1/phi1hat)%exp(-sqrt(3)*h1/phi1hat);\n  mat InvSigma = inv(Sigma);\t   \n  mat Xth = ones(thnrow,1);\n  Xth.insert_cols(1,Designmat);\t \n  \n  for(int k = 0; k< Niter; k++){\n    \n    if( (k > 1000) && (k <= 10000) ){\n      sigma = stddev(theta);\n    }\n    vec Znormal = randn(1);\n    vec thetaprev(1);\n    thetaprev[0] = theta[k];\n    \n    vec thetaprop = thetaprev + Znormal*sigma;\n    \n    if( thetaprop[0] > Domain[1] || thetaprop[0] < Domain[0] ){\n      logprob = negativeInf;\n      \n    }else{\n      for(int i = 0; i< thnrow; i++){\n        h1dcross[i] =  fabs(thetaprop[0]-Designmat(i));\n      }\n      mat Sigmacross = sigmasqhat*(1+sqrt(3)*h1dcross/phi1hat)%exp(-sqrt(3)*h1dcross/phi1hat);\n      vec xpoint = ones(1);\n      xpoint.insert_rows(1,thetaprop);\n      lhXZp = (trans(xpoint)*betahat + trans(Sigmacross)* InvSigma*(y-Xth*betahat))[0];\n      logprob = lhXZp - lhXZ; \n    }\n    \n    u = log( randu() );\n    if( u< logprob ){\n      theta.insert_rows(k+1,thetaprop);\n      lhXZ = lhXZp;\n    }else{\n      theta.insert_rows(k+1,thetaprev);\n    }\n    \n  }\n  \n  return theta;\n}\n\n",
    "created" : 1600440796650.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "473126044",
    "id" : "9825BA8A",
    "lastKnownWriteTime" : 1600434975,
    "last_content_update" : 1600434975,
    "path" : "/storage/work/b/bxk487/approxKSD/ising/RcppFtns.cpp",
    "project_path" : "RcppFtns.cpp",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "cpp"
}